{"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oRpPpTriVwR","executionInfo":{"status":"ok","timestamp":1715781365201,"user_tz":-540,"elapsed":18053,"user":{"displayName":"김의진","userId":"04813843641245492751"}},"outputId":"f29a91eb-5995-410b-9080-b5e50c6d83b7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"Yu9QsdP8hoiW","executionInfo":{"status":"error","timestamp":1715781457918,"user_tz":-540,"elapsed":6942,"user":{"displayName":"김의진","userId":"04813843641245492751"}},"outputId":"434dccc4-00c4-48a3-987c-96521fdf1d40"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/컴퓨터 비전/computer-vision/detr\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'datasets'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-265a19611fd9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/컴퓨터 비전/computer-vision/detr/engine.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco_eval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpanoptic_eval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPanopticEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["%cd /content/drive/MyDrive/컴퓨터 비전/computer-vision/detr\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","import yaml, json, box\n","import util.misc as utils\n","from model import build_model\n","from engine import evaluate, train_one_epoch\n","from dataloader.dataset import CustomDataset\n","\n","DATA_ROOT = \"/content/drive/MyDrive/컴퓨터 비전/data\"\n","\n","def set_dataloader(csv_file, valid = False, batch_size = 16):\n","    def set_tta():\n","        transform = A.Compose(\n","            [\n","              fisheye([-1, 3.5, 0, 0]),\n","              A.CenterCrop(600, 930),\n","              A.Resize(224, 224),\n","              A.Normalize(),\n","              ToTensorV2()\n","            ])\n","        return transform\n","\n","    def set_train_aug():\n","        transform = A.Compose(\n","            [\n","              fisheye([-1, 3.5, 0, 0]),\n","              A.CenterCrop(600, 930),\n","              A.Resize(224, 224),\n","              A.Normalize(),\n","              ToTensorV2()\n","            ])\n","        return transform\n","\n","    if not valid: t = set_train_aug()\n","    else: t = set_tta()\n","\n","    dataset = CustomDataset(data_root = DATA_ROOT, csv_file=csv_file, transform= t, infer=False)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    return dataloader\n","\n","def train(args):\n","    device = torch.device(args.scheduler.device)\n","\n","    model, criterion, postprocessors = build_model(args)\n","    model.to(device)\n","\n","    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print('number of params:', n_parameters)\n","    param_dicts = [\n","        {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n","            \"lr\": args.scheduler.lr_backbone,\n","        },\n","    ]\n","    optimizer = torch.optim.AdamW(param_dicts, lr=args.scheduler.lr,\n","                                  weight_decay=args.scheduler.weight_decay)\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.scheduler.lr_drop)\n","\n","    if args.model.frozen_weights is not None:\n","        checkpoint = torch.load(args.model.frozen_weights, map_location='cpu')\n","        model.detr.load_state_dict(checkpoint['model'])\n","\n","    if args.scheduler.resume:\n","        if args.scheduler.resume.startswith('https'):\n","            checkpoint = torch.hub.load_state_dict_from_url(\n","                args.scheduler.resume, map_location='cpu', check_hash=True)\n","        else:\n","            checkpoint = torch.load(args.scheduler.resume, map_location='cpu')\n","        model.load_state_dict(checkpoint['model'])\n","        if 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n","            optimizer.load_state_dict(checkpoint['optimizer'])\n","            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n","            args.scheduler.start_epoch = checkpoint['epoch'] + 1\n","\n","    ## start ##\n","    data_loader_train = set_dataloader('train_source.csv')\n","    data_loader_valid = set_dataloader('val_source.csv')\n","    print(\"Start training\")\n","    for epoch in range(args.scheduler.start_epoch, args.scheduler.epochs):\n","        train_stats = train_one_epoch(\n","            model, criterion, data_loader_train, optimizer, device, epoch,\n","            args.scheduler.clip_max_norm)\n","\n","        lr_scheduler.step()\n","        utils.save_on_master({\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","            'epoch': epoch,\n","            'args': args,\n","        }, args.scheduler.save_path + 'checkpoint.pth')\n","\n","train()"]},{"cell_type":"code","source":[],"metadata":{"id":"h-nCETyFiLa4"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}