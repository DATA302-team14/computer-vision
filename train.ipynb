{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23930,"status":"ok","timestamp":1715317395542,"user":{"displayName":"김의진","userId":"04813843641245492751"},"user_tz":-540},"id":"w9DwBG6B4ejB","outputId":"7356b022-cf7e-42d5-e31d-11006931da29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/컴퓨터 비전/computer-vision\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"VBhNLAScNA3S"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/컴퓨터 비전/computer-vision\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","  0%|          | 0/119 [00:00\u003c?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","  0%|          | 0/119 [00:32\u003c?, ?it/s]\n"]},{"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-b12581933a04\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 64\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_epoch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 64\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-2-b12581933a04\u003e\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 49\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m           \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["%cd /content/drive/MyDrive/컴퓨터 비전/computer-vision\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from dataloader.dataset import CustomDataset\n","from model.unet import UNet\n","from tool.encode import rle_encode\n","import albumentations as A\n","from PIL import Image\n","from albumentations.pytorch import ToTensorV2\n","\n","SAVE_ROOT = \"/content/drive/MyDrive/컴퓨터 비전/computer-vision/model/checkpoint\"\n","DATA_ROOT = \"/content/drive/MyDrive/컴퓨터 비전/data\"\n","\n","def set_dataloader():\n","    def set_tta():\n","        transform = A.Compose(\n","          [\n","              A.Resize(224, 224),\n","              A.Normalize(),\n","              ToTensorV2()\n","          ])\n","        return transform\n","    test_dataset = CustomDataset(data_root = DATA_ROOT, csv_file='test.csv', transform=set_tta(), infer=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n","    return test_dataloader\n","\n","def set_model():\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = UNet().to(device)\n","    return model, device\n","\n","def train():\n","  model, device = set_model()\n","  train_dataloader = set_dataloader()\n","  model_name = \"unet\"\n","\n","    # loss function과 optimizer 정의\n","  criterion = torch.nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","  # training loop\n","  for epoch in range(20):  # 20 에폭 동안 학습합니다.\n","      model.train()\n","      epoch_loss = 0\n","      for images, masks in tqdm(train_dataloader):\n","          images = images.float().to(device)\n","          masks = masks.long().to(device)\n","\n","          optimizer.zero_grad()\n","          outputs = model(images)\n","          loss = criterion(outputs, masks.squeeze(1))\n","          loss.backward()\n","          optimizer.step()\n","\n","          epoch_loss += loss.item()\n","\n","      print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_dataloader)}')\n","      torch.save(model, os.path.join(SAVE_ROOT, model_name+\"_epoch\"+epoch+\".pt\"))\n","\n","train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9VFLGtV5bkq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMskcGYbQPt1M9Qyh0jtGOF","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}