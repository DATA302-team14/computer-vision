{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMslOTJHLvGzwRKZb4D4KoE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/MyDrive/컴퓨터 비전/computer-vision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_Tu7Xx0xsxd","executionInfo":{"status":"ok","timestamp":1715315663370,"user_tz":-540,"elapsed":24262,"user":{"displayName":"김의진","userId":"04813843641245492751"}},"outputId":"354c3e5d-1421-44a3-eb92-8cc35d36f400"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/컴퓨터 비전/computer-vision\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Crx8cGlNw8uf","executionInfo":{"status":"ok","timestamp":1715316313379,"user_tz":-540,"elapsed":2,"user":{"displayName":"김의진","userId":"04813843641245492751"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from dataloader.dataset import CustomDataset\n","from model.unet import UNet\n","from tool.encode import rle_encode\n","import albumentations as A\n","from PIL import Image\n","from albumentations.pytorch import ToTensorV2\n","\n","def set_dataloader():\n","    def set_tta():\n","        transform = A.Compose(\n","          [\n","              A.Resize(224, 224),\n","              A.Normalize(),\n","              ToTensorV2()\n","          ])\n","        return transform\n","    test_dataset = CustomDataset(csv_file='./test.csv', transform=set_tta(), infer=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n","    return test_dataloader\n","\n","def set_model():\n","    model = UNet()\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    return model, device\n","\n","def inference():\n","  model, device = set_model()\n","  test_dataloader = set_dataloader()\n","\n","  with torch.no_grad():\n","      model.eval()\n","      result = []\n","      for images in tqdm(test_dataloader):\n","          images = images.float().to(device)\n","          outputs = model(images)\n","          outputs = torch.softmax(outputs, dim=1).cpu()\n","          outputs = torch.argmax(outputs, dim=1).numpy()\n","          # batch에 존재하는 각 이미지에 대해서 반복\n","          for pred in outputs:\n","              pred = pred.astype(np.uint8)\n","              pred = Image.fromarray(pred) # 이미지로 변환\n","              pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n","              pred = np.array(pred) # 다시 수치로 변환\n","              # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n","              for class_id in range(12):\n","                  class_mask = (pred == class_id).astype(np.uint8)\n","                  if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n","                      mask_rle = rle_encode(class_mask)\n","                      result.append(mask_rle)\n","                  else: # 마스크가 존재하지 않는 경우 -1\n","                      result.append(-1)\n","  submit = pd.read_csv('./sample_submission.csv')\n","  submit['mask_rle'] = result\n","  submit.to_csv('./baseline_submit.csv', index=False)"]}]}